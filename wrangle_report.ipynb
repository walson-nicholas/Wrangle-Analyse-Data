{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>DATA WRANGLING PROJECT REPORT</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BY: Asimiea Nicholas Walson\n",
    "\n",
    "### INTRODUCTION\n",
    "\n",
    "This project is designed to sharpen the skills we learned from the Data Wrangling module in Udacity's Data Analyst Nanodegree program. In this project, we gathered, assessed, cleaned, analysed and visualized a real-world data using Python and its libraries.\n",
    "\n",
    "The wrangled dataset is the tweet archive of Twitter user [@DogRates](https://twitter.com/dog_rates), also known as [@WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs). WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc.\n",
    "\n",
    "### METHODOLOGY\n",
    "**The following tasks were executed in this project**\n",
    "1. Data Gathering\n",
    "2. Data Assessing\n",
    "3. Data Cleaning\n",
    "4. Drawing Insights from cleaned data\n",
    "5. Using visualization to draw more insights.\n",
    "\n",
    "\n",
    "#### 1. Data Gathering\n",
    "Three different dataset was gathered in three different formats in this project.\n",
    "\n",
    "`The WeRateDogs Twitter archive`: This data was made available in udacity. I first downloaded it into my computer download folder, I then uploaded into the directory where my project is located using the jupyter notebook upload button. The notebook used for the wrangling is called wrangle_act. I used the padas library method **read_csv()** to read the file into a pandas dataframe named df1.\n",
    "\n",
    "\n",
    "`The tweet image predictions`: I downloaded this file programmatically using Python request library. I then wrote the content of the URL response to a file. The file is a tsv file, so therefore, I read the file into a pandas dataframe called df2 using the same method above but this time around, I stated the sep parameter to be equal to tab. I saved this df2 dataframe into a csv file for further visual assessment using excel.\n",
    "\n",
    "\n",
    "`Tweet-json.txt`: This data requires a twitter developer account whichi I applied for but was not successful, I decided to use the one made available for students by udacity in such case. I wrote the provided tweet-json.txt file line by line into a list which I read into a pandas dataframe using the called df3 using pd.DataFrame method. I selected only columns relevant to the project in the dataframe and then saved the file to a csv file for further visual assessement using excel.\n",
    "\n",
    "\n",
    "#### 2. Data Assessing\n",
    "\n",
    "After gathering all three dataset and created the dataframes and csv files for each, I carried out visual and programmatic assessment for each one.\n",
    "\n",
    "**Visual Assessment:** I started with the jupyter notebook using the pandas functions such as .head(), .tail(), .sample(), or by calling the dataframe. This helped me to get a glimpse of the content of each dataframe. I conducted further visual assessments by opening their corresponding csv files using Excel. I documented all data cleanliness issues I observed.\n",
    "\n",
    "\n",
    "**Programmatic Assessment:** I conducted different programmatic assessment using various python and pandas functions such as .info(), .isnull(), .value_counts(), .nunique() .sum(), .duplicated(). I documented all data cleanliness issues I observed.\n",
    "\n",
    "\n",
    "##### **Summary of Data Cleanliness Issues**\n",
    "##### Quality issues\n",
    "`df1 table`\n",
    "1. Missing expanded_urls entries\n",
    "\n",
    "2. Some entries are retweets\n",
    "\n",
    "3. Unnecessary columns (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp)\n",
    "\n",
    "4. Erroneous datatype in tweet_id and timestamp columns\n",
    "\n",
    "5. Incorrect dog names. These are observed for names that start with lowercase.\n",
    "\n",
    "`df2 table`\n",
    "1. Erroneous datatype in tweet_id column\n",
    "\n",
    "2. Entries with FALSE in p1_dog, p2_dog and p3_dog columns are not dog related reviews / ratings.\n",
    "\n",
    "3. Inconsistency format in p1, p2 and p3 entries. Some start with uppercase, some start with lower case.\n",
    "\n",
    "`df3 table`\n",
    "1. Erroneous datatype in id column\n",
    "\n",
    "\n",
    "##### Tidiness issues\n",
    "df1 - one variable in multiple columns (doggo, floofer, pupper and puppo)\n",
    "\n",
    "df3 - inconsistency in column name common in the three dataframes. id column should be tweet_id\n",
    "\n",
    "All dataframe should be merged into one master dataframe\n",
    "\n",
    "\n",
    "#### 3. Cleaning Data\n",
    "\n",
    "The cleaning process is divided into three phase: Define, code and test.\n",
    "This step is where all the observed data cleanliness issues are corrected in order to get e a clean master pandas Dataframe containing only original ratings (no retweets) with images related to dogs. Before starting the cleaning process, copies of the original datasets were made. These are: \n",
    "\n",
    "df1_clean = df1.copy()\n",
    "df2_clean = df2.copy()\n",
    "df3_clean = df3.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
